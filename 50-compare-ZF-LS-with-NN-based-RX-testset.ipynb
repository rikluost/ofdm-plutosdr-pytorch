{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing NN-receiver performance against ZF/LS receiver performance on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from OFDM_SDR_Functions_torch import *\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from models_local import *\n",
    "from OFDM_SDR_Functions_torch import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "\n",
    "# Display the selected device\n",
    "print(device)\n",
    "\n",
    "# Test tensor creation on the selected device\n",
    "if device.type != \"cpu\":\n",
    "    x = torch.ones(1, device=device)\n",
    "    print(x)\n",
    "\n",
    "device = \"cpu\" # Force CPU for now, trouble with converting complex tensors to mps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the testset, model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RXModel(Qm).to(device)\n",
    "\n",
    "TTI_mask_RE = TTI_mask(S=S,F=F, Fp=Fp, Sp=Sp, FFT_offset=FFT_offset, plotTTI=False).to(device) # TTI mask\n",
    "pilot_symbols = pilot_set(TTI_mask_RE, Pilot_Power).to(device) # pilot symbols\n",
    "\n",
    "mapping_table_QPSK, de_mapping_table_QPSK = mapping_table(2) # mapping table QPSK (e.g. for pilot symbols)\n",
    "mapping_table_Qm, de_mapping_table_Qm = mapping_table(Qm, plot=False) # mapping table for Qm\n",
    "\n",
    "# load the testset\n",
    "test_set = torch.load('data/ofdm_testset.pth')\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load the model architecture and weights\n",
    "checkpoint_path = 'data/rx_model_10.pth'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_losses_NN = []\n",
    "test_BERs_NN = []\n",
    "test_BERs_ZFLS = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the testset and measure BER with both receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove DC and FFT offsets from TTI mask_RE and add third dimension size of Qm, and expand TTI mask values into the third dimension\n",
    "TTI_mask_RE_small = TTI_mask_RE[:, FFT_offset:-FFT_offset]\n",
    "middle_index = TTI_mask_RE_small.size(1) // 2\n",
    "TTI_mask_RE_small = torch.cat((TTI_mask_RE_small[:, :middle_index], TTI_mask_RE_small[:, middle_index + 1:]), dim=1)\n",
    "\n",
    "TTI_mask_RE_3d = TTI_mask_RE_small.unsqueeze(-1).expand(S, F-1, Qm)\n",
    "wrongs=[]\n",
    "wrongs_ls=[]\n",
    "with torch.no_grad():\n",
    "    for test_pdsch_iq, test_pilot_iq, test_labels in test_loader:\n",
    "        \n",
    "        # NN receiver ###################################################\n",
    "        test_outputs = model((test_pdsch_iq.to(device), test_pilot_iq.to(device)))\n",
    "        binary_predictions = test_outputs.squeeze()[TTI_mask_RE_3d==1]\n",
    "        binary_predictions = torch.round(binary_predictions)\n",
    "        test_labels = test_labels.squeeze()[TTI_mask_RE_3d==1]\n",
    "\n",
    "        # load a batch of data to the device\n",
    "        test_pdsch_iq, test_pilot_iq, test_labels = test_pdsch_iq.squeeze().to(device), test_pilot_iq.squeeze().to(device), test_labels.squeeze().to(device)\n",
    "\n",
    "        # Calculate Bit Error Rate (BER) for the NN-receiver\n",
    "        error_count = torch.sum(binary_predictions != test_labels).float()  # Count of unequal bits\n",
    "\n",
    "        new_wrongs = (binary_predictions.flatten() != test_labels.flatten()).float().tolist()\n",
    "        wrongs.append(new_wrongs)\n",
    "\n",
    "        \n",
    "        error_rate = error_count / len(test_labels.flatten())  # Error rate calculation\n",
    "        BER_NN = torch.round(error_rate * 1000) / 1000  # Round to 3 decimal places\n",
    "        test_BERs_NN.append(BER_NN.item())\n",
    "\n",
    "        # ZF-LS receiver ####################################################\n",
    "\n",
    "        # add DC and FFT offsets, as channel estimation expects those\n",
    "        test_pdsch_iq_w = torch.cat((torch.zeros(S, FFT_offset, dtype=test_pdsch_iq.dtype, device=device), test_pdsch_iq, torch.zeros(S, FFT_offset, dtype=test_pdsch_iq.dtype, device=device)), dim=1) # add FFT offset\n",
    "        middle_index = test_pdsch_iq_w.size(1) // 2+1\n",
    "        test_pdsch_iq_w = torch.cat((test_pdsch_iq_w[:, :middle_index], torch.zeros(S, 1, device=device), test_pdsch_iq_w[:, middle_index:]), dim=1) # add DC\n",
    "        test_pilot_iq_w = torch.cat((torch.zeros(S, FFT_offset, device=device), test_pilot_iq, torch.zeros(S, FFT_offset, device=device)), dim=1) # add FFT offset\n",
    "        test_pilot_iq_w = torch.cat((test_pilot_iq_w[:, :middle_index], torch.zeros(S, 1, device=device), test_pilot_iq_w[:, middle_index:]), dim=1) # add DC\n",
    "\n",
    "        # combine in one tensor, pdsch and pilot symbols\n",
    "        test_pdsch_iq_w[TTI_mask_RE == 2] = test_pilot_iq_w[TTI_mask_RE == 2]\n",
    "        test_pdsch_iq_w_t = test_pdsch_iq_w\n",
    "        \n",
    "        # calculate channel estimate\n",
    "        H_estim = channelEstimate_LS(TTI_mask_RE, pilot_symbols, F, FFT_offset, Sp, test_pdsch_iq_w, plotEst=False)\n",
    "\n",
    "        # remove FFT offsets\n",
    "        test_pdsch_iq_w = remove_fft_Offests(test_pdsch_iq_w, F, FFT_offset)\n",
    "        \n",
    "        # equalize the received signal\n",
    "        equalized_H_estim = equalize_ZF(test_pdsch_iq_w, H_estim, F, S)\n",
    "\n",
    "        # get the payload symbols \n",
    "        QAM_est = get_payload_symbols(TTI_mask_RE, equalized_H_estim, FFT_offset, F, plotQAM=False)\n",
    "\n",
    "        # demap the symbols\n",
    "        PS_est, hardDecision = Demapping(QAM_est, de_mapping_table_Qm)\n",
    "\n",
    "        # convert to bits\n",
    "        bits_est = torch.tensor(PS(PS_est).flatten().cpu(), dtype=torch.int8)\n",
    "\n",
    "        # Calculate Bit Error Rate (BER) for the ZF-LS receiver\n",
    "        test_labels = torch.tensor(test_labels.flatten().cpu(), dtype=torch.int8)\n",
    "        \n",
    "        new_wrongs_ls = (bits_est != test_labels).float().tolist()\n",
    "        wrongs_ls.append(new_wrongs_ls)\n",
    "        \n",
    "        error_count = torch.sum(bits_est != test_labels).float()  # Count of unequal bits\n",
    "        error_rate = error_count / bits_est.numel()  # Error rate calculation\n",
    "        BER_ZFLS = torch.round(error_rate * 1000) / 1000  # Round to 3 decimal places\n",
    "        test_BERs_ZFLS.append(BER_ZFLS.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## observe if thre are time domain problems, either in the NN, or in the LS receiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,4))\n",
    "plt.plot(np.sum(wrongs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,4))\n",
    "plt.plot(np.sum(wrongs_ls, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the mean BER, illustrate BER distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average test loss and BER\n",
    "average_test_BER_NN = sum(test_BERs_NN) / len(test_BERs_NN)\n",
    "average_test_BER_ZFLS = sum(test_BERs_ZFLS) / len(test_BERs_ZFLS)\n",
    "\n",
    "# Print or log average test loss and BER for both the NN and ZF-LS receiver\n",
    "print('Average test BER NN: {:.4f}'.format(average_test_BER_NN))\n",
    "print('Average test BER ZF-LS: {:.4f}'.format(average_test_BER_ZFLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(test_BERs_NN, bins=120, alpha=0.7, color='blue', label='NN')\n",
    "plt.hist(test_BERs_ZFLS, bins=120, alpha=0.7, color='orange', label='ZF-LS')\n",
    "plt.xlabel('Bit Error Rate (BER)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of BERs for NN and ZF-LS Receivers')\n",
    "plt.legend()\n",
    "plt.xlim(0, 0.1)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.savefig('pics/BER_distribution_testset.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
